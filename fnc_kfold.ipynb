{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from feature_engineering import refuting_features, polarity_features, hand_features, gen_or_load_feats, gen_word2vec_feats\n",
    "from feature_engineering import word_overlap_features\n",
    "from feature_engineering import supporting_features, punctuation_features, question_features, cap_features\n",
    "from feature_engineering import latent_semantic_indexing\n",
    "from utils.dataset import DataSet\n",
    "from utils.generate_test_splits import kfold_split, get_stances_for_folds\n",
    "from utils.score import report_score, LABELS, score_submission\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.neural_network import MLPClassifier \n",
    " \n",
    "from utils.system import parse_params, check_version\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(stances,dataset,name):\n",
    "    h, b, y = [],[],[]\n",
    "\n",
    "    for stance in stances:\n",
    "        y.append(LABELS.index(stance['Stance']))\n",
    "        h.append(stance['Headline'])\n",
    "        b.append(dataset.articles[stance['Body ID']])\n",
    "\n",
    "    X_overlap = gen_or_load_feats(word_overlap_features, h, b, \"features/overlap.\"+name+\".npy\")\n",
    "    X_refuting = gen_or_load_feats(refuting_features, h, b, \"features/refuting.\"+name+\".npy\")\n",
    "    X_polarity = gen_or_load_feats(polarity_features, h, b, \"features/polarity.\"+name+\".npy\")\n",
    "    X_hand = gen_or_load_feats(hand_features, h, b, \"features/hand.\"+name+\".npy\")\n",
    "    \n",
    "    X_supporting = gen_or_load_feats(supporting_features, h, b, \"features/supporting.\"+name+\".npy\")\n",
    "    X_punctuation = gen_or_load_feats(punctuation_features, h, b, \"features/punctuation.\"+name+\".npy\")\n",
    "    X_question = gen_or_load_feats(question_features, h, b, \"features/question.\"+name+\".npy\")\n",
    "    X_cap = gen_or_load_feats(cap_features, h, b, \"features/cap.\"+name+\".npy\")\n",
    "\n",
    "    X_lsi = gen_or_load_feats(latent_semantic_indexing, h, b, \"features/lsi.\"+name+\".npy\")\n",
    "    \n",
    "    headVec, bodyVec, simVec = gen_word2vec_feats(h,b)\n",
    "    X = np.c_[X_hand, X_polarity, X_refuting, X_overlap, X_supporting, X_punctuation, X_question, X_cap, X_lsi, headVec, bodyVec, simVec]\n",
    "    #X = np.c_[X_hand, X_polarity, X_refuting, X_overlap, X_supporting, X_punctuation, X_question, X_cap, X_lsi]\n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n",
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n",
      "generating word2vec features\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "#Load the training dataset and generate folds\n",
    "d = DataSet()\n",
    "folds,hold_out= kfold_split(d,n_folds=10)\n",
    "fold_stances, hold_out_stances = get_stances_for_folds(d,folds,hold_out)\n",
    "\n",
    "# Load the competition dataset\n",
    "competition_dataset = DataSet(\"competition_test\")\n",
    "X_competition, y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n",
      "generating word2vec features\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "Xs = dict()\n",
    "ys = dict()\n",
    "\n",
    "# Load/Precompute all features now\n",
    "X_holdout,y_holdout = generate_features(hold_out_stances,d,\"holdout\")\n",
    "for fold in fold_stances:\n",
    "    Xs[fold],ys[fold] = generate_features(fold_stances[fold],d,str(fold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cv(model, parameters, fold_num):\n",
    "\n",
    "    ids = list(range(len(folds)))\n",
    "    del ids[fold_num]\n",
    "\n",
    "    X_train = np.vstack(tuple([Xs[i] for i in ids]))\n",
    "    y_train = np.hstack(tuple([ys[i] for i in ids]))\n",
    "\n",
    "    X_test = Xs[fold_num]\n",
    "    y_test = ys[fold_num]\n",
    "\n",
    "    scoring = {'acc':'accuracy'}\n",
    "    clf = GridSearchCV(model, parameters, cv=5, scoring=scoring, refit='acc')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'alpha': 1, 'random_state': 42}\n",
      "best score: 0.897301538375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {'alpha':[.1, 1, 10, 100], 'random_state':[42]}\n",
    "\n",
    "m = RidgeClassifier()\n",
    "r_results = apply_cv(m, param, 0)\n",
    "print('best parameters: ' + str(r_results.best_params_))\n",
    "print('best score: '+str(r_results.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'n_clusters': 4, 'random_state': 42}\n",
      "best score: 0.244402723681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "param = {'n_clusters':[4, 5, 6, 7, 8], 'random_state':[42]}\n",
    "\n",
    "m = KMeans()\n",
    "k_results = apply_cv(m, param, 0)\n",
    "print('best parameters: ' + str(k_results.best_params_))\n",
    "print('best score: '+str(k_results.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'n_clusters': 3, 'random_state': 42}\n",
      "best score: 0.0853812312607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "param = {'n_clusters':[1, 2, 3], 'random_state':[42]}\n",
    "\n",
    "m = KMeans()\n",
    "k_2_results = apply_cv(m, param, 0)\n",
    "print('best parameters: ' + str(k_2_results.best_params_))\n",
    "print('best score: '+str(k_2_results.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_depth': 5, 'random_state': 42}\n",
      "best score: 0.864096169473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param = {'criterion':('gini', 'entropy'), 'max_depth':[5, 10, 20, None], 'random_state':[42]}\n",
    "\n",
    "m = DecisionTreeClassifier()\n",
    "d_results = apply_cv(m, param, 0)\n",
    "print('best parameters: ' + str(d_results.best_params_))\n",
    "print('best score: '+str(d_results.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'max_depth': 5, 'n_estimators': 200, 'seed': 42}\n",
      "best score: 0.92193235632\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier \n",
    "\n",
    "param = {'n_estimators':[10, 50, 100, 200], 'max_depth': [2, 3, 5], 'seed':[42]}\n",
    "\n",
    "m = XGBClassifier()\n",
    "x_results = apply_cv(m, param, 0)\n",
    "print('best parameters: ' + str(x_results.best_params_))\n",
    "print('best score: '+str(x_results.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'activation': 'logistic', 'random_state': 42}\n",
      "best score: 0.918990108443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "param = {'activation':('relu', 'tanh', 'logistic'), 'random_state':[42]}\n",
    "\n",
    "m = MLPClassifier()\n",
    "m_results = apply_cv(m, param, 0)\n",
    "print('best parameters: ' + str(m_results.best_params_))\n",
    "print('best score: '+str(m_results.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(model):\n",
    "    res = []\n",
    "    best_score = 0\n",
    "    best_fold = None\n",
    "\n",
    "    # Classifier for each fold\n",
    "    for fold in [0, 1, 2]:\n",
    "        ids = list(range(len(folds)))\n",
    "        del ids[fold]\n",
    "\n",
    "        X_train = np.vstack(tuple([Xs[i] for i in ids]))\n",
    "        y_train = np.hstack(tuple([ys[i] for i in ids]))\n",
    "\n",
    "        X_test = Xs[fold]\n",
    "        y_test = ys[fold]\n",
    "\n",
    "        clf = model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        predicted = [LABELS[int(a)] for a in clf.predict(X_test)]\n",
    "        actual = [LABELS[int(a)] for a in y_test]\n",
    "\n",
    "        fold_score, _ = score_submission(actual, predicted)\n",
    "        max_fold_score, _ = score_submission(actual, actual)\n",
    "\n",
    "        score = fold_score/max_fold_score\n",
    "\n",
    "        print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_fold = clf\n",
    "\n",
    "    res.append(best_fold)\n",
    "            \n",
    "    #Run on Holdout set and report the final score on the holdout set\n",
    "    predicted = [LABELS[int(a)] for a in best_fold.predict(X_holdout)]\n",
    "    actual = [LABELS[int(a)] for a in y_holdout]\n",
    "    \n",
    "    res.append(accuracy_score(actual, predicted))\n",
    "    res.append(precision_score(actual, predicted, average='macro'))\n",
    "    res.append(recall_score(actual,predicted, average='macro'))\n",
    "    \n",
    "    #Run on competition dataset\n",
    "    predicted = [LABELS[int(a)] for a in best_fold.predict(X_competition)]\n",
    "    actual = [LABELS[int(a)] for a in y_competition]\n",
    "    \n",
    "    res.append(accuracy_score(actual, predicted))\n",
    "    res.append(precision_score(actual, predicted, average='macro'))\n",
    "    res.append(recall_score(actual,predicted, average='macro'))\n",
    "\n",
    "    print('done!')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 6 was - 0.8030738293593795\n",
      "Score for fold 0 was - 0.845305221868105\n",
      "Score for fold 7 was - 0.8277471361900721\n",
      "Score for fold 5 was - 0.791899852724595\n",
      "Score for fold 2 was - 0.8418144809537657\n",
      "Score for fold 8 was - 0.8373333333333334\n",
      "Score for fold 9 was - 0.8124476695506558\n",
      "Score for fold 3 was - 0.834975037107003\n",
      "Score for fold 1 was - 0.83056292778321\n",
      "Score for fold 4 was - 0.8298755186721992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "Score for fold 6 was - 0.2997701809824763\n",
      "Score for fold 0 was - 0.2712674675165482\n",
      "Score for fold 7 was - 0.24423702446612927\n",
      "Score for fold 5 was - 0.2948453608247423\n",
      "Score for fold 2 was - 0.3498109915673161\n",
      "Score for fold 8 was - 0.2673015873015873\n",
      "Score for fold 9 was - 0.3371476416410829\n",
      "Score for fold 3 was - 0.35258399676157065\n",
      "Score for fold 1 was - 0.2660986171252968\n",
      "Score for fold 4 was - 0.29431964515667475\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "ridge_c = model_score(RidgeClassifier(alpha=1, random_state=42))\n",
    "kmeans_c = model_score(KMeans(n_clusters=4, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 0 was - 0.8746016180436381\n",
      "Score for fold 1 was - 0.8807095963123341\n",
      "Score for fold 2 was - 0.8694387903460308\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "xgb_c = model_score(XGBClassifier(max_depth=5, n_estimators=200, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 0 was - 0.8704339298847756\n",
      "Score for fold 1 was - 0.8699539041765609\n",
      "Score for fold 2 was - 0.8793253852864205\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "mlp_c = model_score(MLPClassifier(activation='logistic', random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RidgeClassifier(alpha=1, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=42, solver='auto',\n",
       "         tol=0.001),\n",
       " 0.88702972355019749,\n",
       " 0.57920530134908732,\n",
       " 0.53577582462057427,\n",
       " 0.86640695706921655,\n",
       " 0.53703241288873871,\n",
       " 0.51489075956426922]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67008344e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_acc = ['ridge', 'kmeans', 'xgb','mlp']\n",
    "Y_acc = [ridge_c[3], kmeans_c[3], xgb_c[3], mlp_c[3]]\n",
    "\n",
    "plt.bar(X_acc, Y_acc)\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc = ['ridge', 'kmeans', 'xgb','mlp']\n",
    "Y_acc = [ridge_c[3], kmeans_c[3], xgb_c[3], mlp_c[3]]\n",
    "\n",
    "plt.bar(X_acc, Y_acc)\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
